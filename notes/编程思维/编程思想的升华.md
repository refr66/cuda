#### **第二幕：编程思想的升华 - Block 级原语与协作组 (Cooperative Groups)**

我们已经掌握了 Warp-level 的 `shuffle` 和 Block-level 的 `__syncthreads`。但如果我们的并行模式更复杂呢？比如，我们想在一个 Block 内部，让不同的 Warp 组成小组，各自独立地进行规约，然后再由一个“领导” Warp 来汇总？

**协作组 (Cooperative Groups)** 是从 CUDA 9 开始引入的一个强大的编程模型，它将这种思想形式化和通用化了。

*   **是什么**: 它是一个**线程组的抽象**。你可以获取代表“整个 Grid”、“当前 Block”、“当前 Warp”甚至“任意大小的、连续的线程分区”的组对象。
*   **核心功能**: 在这个组对象上，你可以调用**集体的、带作用域的**操作。
    *   `group.sync()`: 只同步该组内的线程。
    *   `coalesced_reduce(group, val, op)`: 在该组内执行一次高效的规约。
    *   `coalesced_scan(group, val, op)`: 在该组内执行一次前缀和。

**用 Cooperative Groups 重写 Block 规约**:

```c++
#include <cooperative_groups.h>
namespace cg = cooperative_groups;

__global__ void reduce_cooperative_groups(const float* in, float* out, int n) {
    // 1. 获取当前线程块的组对象
    cg::thread_block block = cg::this_thread_block();
    float sum = 0;
    
    // 2. 并行加载和初步求和
    int i = block.group_index().x * block.size() + block.thread_rank();
    for (; i < n; i += gridDim.x * block.size()) {
        sum += in[i];
    }
    
    // 3. 在整个 Block 内部，调用集体的 reduce 操作
    float total_sum = cg::reduce(block, sum, cg::plus<float>());
    
    // 4. 只有 0 号线程写回最终结果
    if (block.thread_rank() == 0) {
        out[block.group_index().x] = total_sum;
    }
}
```

**代码剖析与优势**:
*   **代码极大简化**: 我们不再需要手写 `for` 循环、处理 `__syncthreads`、担心 Warp Divergence。我们只需声明我们的意图——“我想在这个 Block 内部，对每个线程的 `sum` 变量，执行一次加法规约”。
*   **抽象与性能**: `cg::reduce` 的背后，是 NVIDIA 工程师编写的、为特定硬件深度优化的实现。它会自动地、高效地组合使用 Shared Memory 和 Warp-level 原语，来完成这个任务。你获得了代码的**可读性和可维护性**，而**没有牺牲性能**。
*   **灵活性**: Cooperative Groups 最强大的地方在于它的组合性。你可以将一个 Block 划分为多个 `cg::tiled_partition<32>(block)`，每个分区都是一个 Warp 大小的组。然后你可以在每个分区内并行地执行操作，再在分区之间进行同步。这为实现复杂的并行算法（如分块 FFT、稀疏矩阵运算等）提供了极其强大和清晰的编程模型。
