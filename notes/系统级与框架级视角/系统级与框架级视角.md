在 AI 系统中，CUDA 代码不是独立存在的，它需要和整个系统协同工作。

*   **分布式训练 (Distributed Training)**：
    *   **NCCL (NVIDIA Collective Communications Library)**：当模型大到无法装入单个 GPU，或者需要用多机多卡加速训练时，必须进行分布式计算。NCCL 提供了高度优化的、跨 GPU 和跨节点的通信原语，如 `AllReduce`, `Broadcast`, `AllGather`。
    *   **理解通信拓扑**：熟悉 `NVLink`, `NVSwitch`, `InfiniBand` 等硬件，并知道如何根据硬件拓扑来优化通信模式，是分布式训练性能的关键。

*   **与深度学习框架的集成 (Integration with DL Frameworks)**：
    *   **自定义算子 (Custom Ops)**：几乎所有的 AI 系统开发都基于 PyTorch, TensorFlow 等框架。当遇到框架中没有的、或者性能不满足需求的算子时，你需要用 CUDA 编写自定义算子，并将其封装成可以被 Python 调用的接口。
    *   **工具**：PyTorch C++ Extensions, `torch.utils.cpp_extension` 等工具简化了这个过程，但你仍需处理 C++/CUDA 代码和 Python 的交互（如 Tensor 数据指针的传递）。